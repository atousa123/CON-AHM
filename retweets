install.packages("academictwitteR")
library(academictwitteR)
install.packages("jsonlite")
library(jsonlite)
install.packages("rjson")
library(rjson)
install.packages("httr")
library(httr)
install.packages("ggplot2")
library(ggplot2)
install.packages("plyr")
library(plyr)
install.packages("dplyr")
library(dplyr)
install.packages("stringr")
library(stringr)
install.packages("rtweet")
library(rtweet)
install.packages("twitteR")
library(twitteR)
install.packages("magrittr")
library(magrittr)
install.packages("lubridate")
library(lubridate)
install.packages("arules")
install.packages("arulesViz")
install.packages("tidyverse")
install.packages("purrr")

# Loading package
library(arules)
library(arulesViz)
library(tidyverse)
library(purrr)
library(readxl)
library(knitr)

install.packages("tm")
install.packages("igraph")
install.packages("ggplot2")

library(tm)
library(igraph)
library(ggplot2)
install.packages("tidytext")

library(tidytext)

install.packages("stringr")
library(stringr)

# bind json files in the directory "data" into a data frame containing tweets
bind_tweets(data_path = "C:\\Users\\atoos\\OneDrive\\Desktop\\American Heart Month data json")
# bind json files in the directory "data" into a data frame containing user information
bind_tweets(data_path = "C:\\Users\\atoos\\OneDrive\\Desktop\\American Heart Month data json", user = TRUE)
# bind json files in the directory "data" into a "tidy" data frame / tibble
tweets_AmericanHeartMonth <- bind_tweets(data_path = "C:\\Users\\atoos\\OneDrive\\Desktop\\American Heart Month data json", user = TRUE, output_format = "tidy")


AHM_retweets <- tweets_AmericanHeartMonth %>% select (text, created_at, lang, retweet_count) %>% filter (lang %in% c("en"), tweets_AmericanHeartMonth$retweet_count > 0) %>% na.omit() 


##create pattern to search hashtags within text
hashtag_pat <- "#[a-zA-Z0-9_-ー\\.]+"
hashtag_retweets <- str_extract_all(AHM_retweets$text, hashtag_pat)
hashtag_word_retweets <- unlist(hashtag_retweets)
hashtag_word_retweets <- tolower(hashtag_word_retweets)
hashtag_word_retweets <- gsub("[[:punct:]ー]", "", hashtag_word_retweets)
hashtag_word_retweets <- hashtag_word_retweets[!str_detect(hashtag_word_retweets, "AmericanHeartMonth")]

glimpse(hashtag_word_retweets)

hashtag_count_retweets <- table(hashtag_word_retweets)
top_10_hashtag_retweets <- sort(hashtag_count_retweets, decreasing = TRUE)[1:10]
top_10_hashtag_retweets

as.data.frame(hashtag_word_retweets) %>%
  count(hashtag_word_retweets, sort = TRUE) %>%
  mutate(hashtag_word_retweets = reorder(hashtag_word_retweets, n)) %>%
  top_n(10) %>%
  ggplot(aes(x = hashtag_word_retweets, y = n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Count",
       y = "Hashtag_retweets",
       title = "Top 10 hashtags used in retweets with #AmericanHeartMonth")

corpus <- Corpus(VectorSource(hashtag_retweets))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
dtm <- DocumentTermMatrix(corpus)
cooc_matrix <- crossprod(as.matrix(dtm))

# Create an adjacency matrix
adjacency_matrix <- as.matrix(cooc_matrix)

# Create an igraph graph
g1 <- graph.adjacency(adjacency_matrix, weighted = TRUE, mode = "undirected")

# You can also filter the network to remove low-weight edges to reduce noise
# Set your desired threshold value
threshold_value <- 0.5  # Adjust this value as needed

# Filter the network to remove low-weight edges
g1 <- delete_edges(g1, E(g1)[weight < threshold_value])

# Remove nodes with degrees below a certain threshold (e.g., degree < 5)
g1 <- delete_vertices(g1, V(g1)[degree(g1) < 556])

# Plot the network
plot(g1, layout = layout.fruchterman.reingold, edge.arrow.size = 0.1)

saveRDS(hashtag_retweets, file = "hashtag_retweets_quotes.rds")
saveRDS(hashtag_count_retweets, file = "hashtag_count_retweets_quotes.rds")
saveRDS(hashtag_word_retweets, file = "hashtag_word_retweets_quotes.rds")

install.packages("igraph")
library(igraph)
# Create a graph object from your data
con_graph <- graph_from_data_frame(hashtag_count_retweets, directed = FALSE)
num_nodes <- vcount(con_graph)

num_edges <- ecount(con_graph)

cat("Number of nodes (hashtags):", num_nodes, "\n")
cat("Number of edges (co-occurrences):", num_edges, "\n")

con_density <- graph.density(con_graph)
cat("Density of the Co-Occurrence Network:", con_density, "\n")




